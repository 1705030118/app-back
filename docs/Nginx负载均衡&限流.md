# limit_req限制用户请求速率
> Nginx使用limit_req_zone对同一IP访问进行限流。
Nginx限速使用 Leaky（唝水桶）算法，比喻为水桶顶部倒水，底部漏水，如果倒入水的速率超过漏水的速度，则水桶漏出。
在电信网络和分组交换网络中，带宽有限的情况下该算法使用场景较多。 就请求处理而言，水代表客户端的请求，
存水的桶按先进先出（FIFO）调度算法处理的队列。漏出的水表示退出缓冲区等服务器处理，
而溢出表示请被丢弃且不再提供服务。
# 实现
```
http {
    // 轮询
	upstream server1 {    
        server  192.168.164.129:9999;
        server  192.168.164.134:9999;
       }
    // 区域名称为one（自定义），占用空间大小为10m，平均处理的请求频率不能超过每秒一次。
    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;
    server {
        location /search/ {
            limit_req zone=one burst=5;// 缓冲队列的长度为5
        }
    }
}
```
# 负载均衡算法
> 在高并发情况下需要使用，其原理就是将并发请求分摊到多个服务器执行，减轻每台服务器的压力，多台服务器(集群)共同完成工作任务，从而提高了数据的吞吐量。
- 轮询

所有请求被依次分发到每台应用服务器上， 即每台服务器需要处理的请求数目都相 同， 适合于所有服务器硬件都相同的场景。
- 加权轮询

根据应用服务器硬件性能的情况， 在轮询的基础上， 按照配置的权重将请求分发到每个服务器， 高性能的服务器能分配更多请求。
- 随机

请求被随机分配到各个应用服务器， 在许多场合下， 这种方案都很简单实用， 因为 好的随机数本身就很均衡。 即使应用服务器硬件配置不同，也可以使用加权随机算法。
- 最少连接

记录每个应用服务器正在处理的连接数（请求数）， 将新到的请求分发到最少连接的 服务器上， 应该说， 这是最符合负载均衡定义的算法。 同样， 最少连接算法也可以实现 加权最少连接。
- 源地址散列

根据请求来源的IP地址进行Hash计算， 得到应用服务器， 这样来自同一个IP地址的请求总在同一个服务器上处理。
# 常见的优化配置
- worker_processes

一般调整到与CPU的颗数相同
- 启用gzip压缩

压缩文件大小，减少了客户端http的传输带宽，因此提高了页面加载速度
- 禁用access_logs

访问日志记录，它记录每个nginx请求，因此消耗了大量CPU资源，从而降低了nginx性能。
- sendfile系统调用

可以启用Linux上的sendfile系统调用来发送文件，它减少了内核态与用户态之间的两次内存复制，这样就会从磁盘中读取文件后直接在内核态发送到网卡设备，提高了发送文件的效率
# 负载
负载就是cpu在一段时间内正在处理以及等待cpu处理的进程数之和的统计信息
## cpu使用率低负载高
等待磁盘I/O完成的进程过多，导致进程队列长度过大，但是cpu运行的进程却很少，这样就体现到负载过大了，cpu使用率低。

cpu低而负载高也就是说等待磁盘I/O完成的进程过多，就会导致队列长度过大，这样就体现到负载过大了，但实际是此时cpu被分配去执行别的任务或空闲。

通过top观察cpu很空闲，但是负载比较高的情况：

load average 是对 CPU 负载的评估，其值越高，说明其任务队列越长，处于等待执行的任务越多。