> Feed流是一个目前非常常见的功能，在众多产品中都有展现，通过Feed流可以把动态实时的传播给订阅者，是用户获取信息流的一种有效方式。在大数据时代，如何打造一个千万级规模的Feed流系统仍然是一个挑战。
# 推送
推送系统需要的功能有两个，一个是发布Feed，一个是读取Feed流。对于提送系统，仍然有一些问题需要在选型之前考虑：
- 如何才能提供千万的TPS和QPS？
- 如何保证读写延迟在10ms，甚至2ms以下？
- 如何保证Feed的必达性？
# 存储系统选择
我们接下来解决之前提出来的问题。    
Feed流系统中需要存储的系统有两类，一类是账号关系（比如关注列表），一类是Feed消息。
# 存储账号关系
我们先来看账号关系（比如关注列表）的存储，对于账号关系，它有一些特点：
- 是一系列的变长链表，长度可达亿级别。
- 这样就会导致数据量比较大，但是关系极其简单。
- 还有一点是性能敏感，直接影响关注，取关的响应速度。 从上面这些特征看的话，最适合存账号关系（关注列表）的系统应该是分布式NoSQL数据库：可以存储海量数据，关系简单不需要复杂的join，关键是性能极佳，对内设计实现简单，对外用户体验好。 

除了上面这些特点外，还有一个特点：
- 有序性：有序性并不要求具有排序功能，只需要能按照主键排序就行，只要能按照主键排序，那么关注列表和粉丝列表的顺序就是固定的，可预期的。
# 推模式
从发给第一个粉丝到发给最后一个粉丝可能要几分钟时间（一亿粉丝，100万行每秒，需要100秒），还要为最大并发预留好资源，如果使用表格存储，因为是云服务，则不需要考虑预留最大额度资源的问题。
# 适用场景
通过上述两个方案的对比后，总结下各个方案的适用场景：
- 拉模式：
    - 很多Feed流产品的第一版会采用这种方案，但很快就会抛弃。
    - 另外，拉模式 + 图计算 就会是另一番天地，但是这个时候重心就是图计算了。
- 推模式：
    - Feed流系统中最常用、有效的模式；
    - 用户关系数比较均匀，或者有上限，比如朋友圈；
    - 偏推荐类，同一个Feed对不同用户价值不同，需要为不同用户计算分数，比如pinterest。
- 推拉结合
    - 大部分用户的账号关系都是几百个，但是有个别用户是1000万以上，比如微博。
    - 对大V采用拉模式，普通用户使用推模式。
    - 对活跃粉丝采用推模式，非活跃粉丝采用拉模式（这种方式可以较好的避免大流量对平台的冲击）
# 发布Feed流程
当你发布一条Feed消息的时候，流程是这样的： 
1. Feed消息先进入一个队列服务。 
2. 先从关注列表中读取到自己的粉丝列表，以及判断自己是否是大V。   
3. 将自己的Feed消息写入个人页Timeline（发件箱）。如果是大V，写入流程到此就结束了。   
4. 如果是普通用户，还需要将自己的Feed消息写给自己的粉丝，如果有100个粉丝，那么就要写给100个用户，包括Feed内容和Feed ID。    
5. 第三步和第四步可以合并在一起，使用BatchWriteRow接口一次性将多行数据写入TableStore。    
6. 发布Feed的流程到此结束。    
# 读取Feed流流程
当刷新自己的Feed流的时候，流程是这样的：  
1. 先去读取自己关注的大V列表    
2. 去读取自己的收件箱，只需要一个GetRange读取一个范围即可，范围起始位置是上次读取到的最新Feed的ID，结束位置可以使当前时间，也可以是MAX，建议是MAX值。由于之前使用了主键自增功能，所以这里可以使用GetRange读取。 
3. 如果有关注的大V，则再次并发读取每一个大V的发件箱，如果关注了10个大V，那么则需要10次访问。 
4. 合并2和3步的结果，然后按时间排序，返回给用户。 
至此，使用推拉结合方式的发布，读取Feed流的流程都结束了。
# 参考
[如何打造千万级Feed流系统](https://zhuanlan.zhihu.com/p/30226315)
